{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556332e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crisp\\visualStudioCode\\pipeline\\task-1\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments, BatchSamplers\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ad3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts loaded: 67\n",
      "Training samples: 60\n",
      "Validation samples: 7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(\"chunked-docs/semantic_chunks_combined.jsonl\", lines=True)\n",
    "texts = df[\"chunk_text\"].tolist()\n",
    "\n",
    "print(f\"Total texts loaded: {len(texts)}\")\n",
    "\n",
    "# Train-test split (90-10)\n",
    "train_texts, val_texts = train_test_split(texts, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_texts)}\")\n",
    "print(f\"Validation samples: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0392b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: Dataset({\n",
      "    features: ['anchor', 'positive'],\n",
      "    num_rows: 60\n",
      "})\n",
      "Val dataset: Dataset({\n",
      "    features: ['anchor', 'positive'],\n",
      "    num_rows: 7\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_data = {\n",
    "    \"anchor\": train_texts,\n",
    "    \"positive\": train_texts,  # In production, use actual positive pairs\n",
    "}\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "\n",
    "# Create validation dataset\n",
    "val_data = {\n",
    "    \"anchor\": val_texts,\n",
    "    \"positive\": val_texts,\n",
    "}\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "\n",
    "print(f\"Train dataset: {train_dataset}\")\n",
    "print(f\"Val dataset: {val_dataset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ab3918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "print(f\"Model loaded: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efca4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SentenceTransformerTrainingArguments(\n",
    "    # Required: output directory\n",
    "    output_dir=\"models/miniLM_finetuned\",\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    "    # GPU optimization (adjust based on your GPU)\n",
    "    fp16=True,  # Set to False if your GPU can't handle FP16\n",
    "    bf16=False,  # Set to True if your GPU supports BF16\n",
    "    \n",
    "    # Use NO_DUPLICATES for losses with in-batch negatives\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "    \n",
    "    # Evaluation & saving\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,  # Keep only 2 best checkpoints\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"./logs\",\n",
    "    run_name=\"miniLM-semantic-chunks\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e85efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough validation samples for evaluator (need >=30)\n"
     ]
    }
   ],
   "source": [
    "if len(val_texts) >= 30:\n",
    "    evaluator = TripletEvaluator(\n",
    "        anchors=val_texts[:10],\n",
    "        positives=val_texts[:10],\n",
    "        negatives=val_texts[10:20],\n",
    "        name=\"val-triplets\",\n",
    "    )\n",
    "else:\n",
    "    evaluator = None\n",
    "    print(\"Not enough validation samples for evaluator (need >=30)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755770c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have set `args.eval_strategy` to IntervalStrategy.STEPS, but you didn't provide an `eval_dataset` or an `evaluator`. Either provide an `eval_dataset` or an `evaluator` to `SentenceTransformerTrainer`, or set `args.eval_strategy='no'` to skip evaluation.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer = \u001b[43mSentenceTransformerTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crisp\\visualStudioCode\\pipeline\\task-1\\venv\\Lib\\site-packages\\sentence_transformers\\trainer.py:258\u001b[39m, in \u001b[36mSentenceTransformerTrainer.__init__\u001b[39m\u001b[34m(self, model, args, train_dataset, eval_dataset, loss, evaluator, data_collator, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# super.__init__() will still raise a ValueError if `eval_dataset` is None, `evaluator` is None,\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# while eval_strategy is not \"no\", so let's get ahead of it with a more useful ST-specific error message\u001b[39;00m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m evaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m args.eval_strategy != \u001b[33m\"\u001b[39m\u001b[33mno\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    259\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou have set `args.eval_strategy` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs.eval_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but you didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt provide an `eval_dataset` or an `evaluator`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEither provide an `eval_dataset` or an `evaluator` to `SentenceTransformerTrainer`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    261\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor set `args.eval_strategy=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mno\u001b[39m\u001b[33m'\u001b[39m\u001b[33m` to skip evaluation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m     )\n\u001b[32m    264\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**super_kwargs)\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# If the eval_dataset is \"dummy\", then we set it back to None\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: You have set `args.eval_strategy` to IntervalStrategy.STEPS, but you didn't provide an `eval_dataset` or an `evaluator`. Either provide an `eval_dataset` or an `evaluator` to `SentenceTransformerTrainer`, or set `args.eval_strategy='no'` to skip evaluation."
     ]
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset if evaluator else None,\n",
    "    loss=loss,\n",
    "    evaluator=evaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb810b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aec4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"models/miniLM_finetuned/final\")\n",
    "print(\"Model saved to: models/miniLM_finetuned/final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
